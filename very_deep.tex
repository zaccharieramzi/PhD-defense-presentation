\section{Going even deeper}
\subsection{Implicit models}

\begin{frame}{Why should we go deeper?}
    % with deeper models, comes better performance
    % figure of Pezzotti et al.
\end{frame}

\begin{frame}{Can we go deeper?}
    % in the current state not: activations + constrained memory
\end{frame}

\begin{frame}{The modeling solutions}
    % gradient checkpointing
    % Invertible networks
    % Implicit models
\end{frame}

\begin{frame}{Deep Equilibrium networks}
    % give equation and how to compute the gradient with IFT
\end{frame}

\subsection{SHINE}
\begin{frame}{The limits of DEQs}
    % they are slow to train
\end{frame}

\begin{frame}{Why are DEQs slow?}
    % bc of Jacobian inversion
\end{frame}

\begin{frame}{Can we avoid the Jacobian inversion?}
    % yes: reuse a by-product of the forward pass, share the inverse estimate
\end{frame}

\begin{frame}{Application to Hyperparameter optimization}
    % it's also a bilevel prob
\end{frame}

\begin{frame}{Results on DEQs}

\end{frame}