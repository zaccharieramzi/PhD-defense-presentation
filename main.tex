%----------------------------------------------------------------------------------------
%	PACKAGES AND THEMES
%----------------------------------------------------------------------------------------
\documentclass[aspectratio=169,xcolor=dvipsnames]{beamer}
\usetheme{SimplePlus}

\usepackage{amsmath,amssymb,amsfonts,amsthm}
\usepackage{bbm}
\usepackage{mathtools}
\usepackage{xspace}
\usepackage{dsfont}
\usepackage{pifont}
\usepackage{hyperref}
\usepackage{graphicx} % Allows including images
\usepackage{booktabs} % Allows the use of \toprule, \midrule and \bottomrule in tables
\usepackage{fontawesome}
\usepackage{multicol}
\usepackage[
	backend=biber, 
	style=alphabetic, 
	natbib=true, 
	backref=True,
	hyperref=true,
	url=false,
	isbn=false,
	maxcitenames=1,
	maxbibnames=100,
	giveninits=true,
]{biblatex}
\preto\fullcite{\AtNextCite{\defcounter{maxnames}{99}}}
\include{./bold_alphabet}
\include{./abrmath}
\include{./eq_annotate}
\usepackage{tikz}
\usetikzlibrary{tikzmark}
%----------------------------------------------------------------------------------------
%	TITLE PAGE
%----------------------------------------------------------------------------------------

\title[Advanced deep neural networks for MRI image reconstruction]{Advanced deep neural networks for MRI image reconstruction from highly undersampled data in challenging acquisition settings
} % The short title appears at the bottom of every slide, the full title is only on the title page
\subtitle{PhD defense}

\author[Zaccharie] {Zaccharie Ramzi}
% XXX: add supervisors
% XXX: add university and ED
\institute[Inria-CEA] % Your institution as it will appear on the bottom of every slide, may be shorthand to save space
{
    Parietal team, Inria Saclay \\
    NeuroSpin and Cosmostat, CEA Saclay
}
\date{18th February 2022} % Date, can be changed to a custom date

\addbibresource{ThesisBib.bib}
\addbibresource{websites.bib}


\setbeamerfont{subsection in toc}{size=\small}
\setbeamerfont{section in toc}{size=\large}
\setbeamertemplate{blocks}[rounded]%
[shadow=true]


% debug
% \makeatletter
% \begingroup
% \edef\get@@version{\def\noexpand\get@version##1\detokenize{TeX Live}##220##3##4##5)##6\noexpand\@nil}
% \get@@version{\gdef\TeXLiveVersion{20#3#4}}
% \expandafter\get@version\pdftexbanner\@nil
% \endgroup
% \makeatother

%----------------------------------------------------------------------------------------
%	PRESENTATION SLIDES
%----------------------------------------------------------------------------------------

\begin{document}

\begin{frame}
    % Print the title page as the first slide
    \titlepage
    % XXX: add logos
\end{frame}

% Introduction: the problem at hand
% Introduction: physics of MRI
% Acceleration: classics
% Acceleration: CS
% Deep Learning
% Application of DL to MRI: model agnostic, single domain and unrolled networks
% Clinical applicability
% Going further !
% CCL
{
\usebackgroundtemplate{\includegraphics[width=\paperwidth]{Figures/inside_mri.png}}
\begin{frame}[plain]
    % I would like to have the picture of inside the MRI
    % and pass the sound of an MRI scan
    %  \href{run:sons/extract.mp3}{\beamerbutton{Ã©couter}} (https://texnique.fr/osqa/questions/2988/du-son-dans-beamer)
    % https://www.francetvinfo.fr/sante/malgre-l-augmentation-des-besoins-medicaux-le-deficit-en-france-d-appareils-irm-se-fait-de-plus-en-plus-sentir_220301.html
    \href{run:Sounds/mri_sounds.mp3}{\faPlayCircle}
    % XXX: add credit to image
\end{frame}
}

% link between the 2: this is the sound you hear when undergoing an MRI
% now imagine that you will on average hear this during x minutes
% MRI scanners being slow not only generate discomfort but have other impacts on their efficiency...
\begin{frame}{MRI is slow}
    % for debug
    % This has been run with \TeX~Live~\TeXLiveVersion.
    Typical MRI~(Magnetic Resonance Imaging) scan duration: 15 minutes (up to 90 minutes).
    Hence:
    \begin{itemize}
        \item discomfort \& accessibility issues;
        \item reduced patient throughput;
        \item increased motion.
    \end{itemize}
    % give typical duration (compare to CT)
    % give associated problems
    % XXX: add citation for duration
\end{frame}

\begin{frame}{Our objective: accelerate MRI scans}
    % give TOC
    \begin{multicols}{2}
    \tableofcontents
    \end{multicols}
\end{frame}

\section{Introduction to MRI}
\begin{frame}{What does an MRI look like?}
    \begin{figure}
        \centering
        \includegraphics[height=0.6\textheight]{Figures/intro_figures/example_knee_fastmri.pdf}
        \caption{\label{fig:mri-example} \textbf{Example of an MR image}: MR image of the knee taken from the fastMRI dataset.\footfullcite{Zbontar}}
    \end{figure}
\end{frame}

\subsection{Importance of MRI}
\begin{frame}{Importance of MRI - 1}
    % how many MRI scans / scanners
    % how likely is it that you will get an MRI in your life
    Based on a rough extrapolation of the following figure, there is a 99.9\% chance that you will get an MRI in your life in France.
    \begin{figure}
        \centering
        \includegraphics[width=\textwidth]{Figures/intro_figures/num_mri_scans.png}
        \caption{\label{fig:num-mri-scans} \textbf{Number of MRI scans per year per 1000 population}: figure courtesy of \citet{OECDMRI}.}
    \end{figure}
\end{frame}

% There is a reason for that: MRI can help diagnose many different conditions
\begin{frame}{Importance of MRI - 2}
    % list of conditions
    \begin{figure}
        \centering
        \includegraphics[height=0.6\textheight]{Figures/intro_figures/What_can_we_diagnose_with_MRI.pdf}
        \caption{\label{fig:diagnose-mri} \textbf{What can we diagnose with MRI?} This illustration provides a non-exhaustive list of all the diagnoses that can be carried out with MRI. All the information was compiled from the works of \citet{reimer2010clinical,runge2019essentials}.}
    \end{figure}
\end{frame}

\subsection{Physics of MRI}
% MRI is so popular why isnt it solved already ?
\begin{frame}{Physics of MRI - 1}
    % at its core MRI relies on the MR phenomenon
    % in short: a spin is aligned with the magnetic field, when an RF pulse is sent, it tips the spin in the orthogonal plane before the spin realigns with the magnetic field sending another RF pulse
    \only<1>{
    \begin{figure}
        \centering
        \includegraphics[width=0.14\textwidth]{Figures/intro_figures/Precession_in_magnetic_field.pdf}
        \caption{\label{fig:precession}\textbf{Illustration of the precession of a spin in a magnetic field:} the green arrow represents the $\Bb_0$ magnetic field, while the black arrow represents the magnetic moment of the particle. Illustration courtesy of \citet{wiki}.}
    \end{figure}
    }
    % XXX: add vspace somewhere to avoid the jump effect
    \only<2>{
    \begin{figure}
        \centering
        \includegraphics[width=0.5\textwidth]{Figures/intro_figures/Excitation.pdf}
        \caption{\label{fig:excitation}\textbf{Illustration of the excitation phenomenon:} the blue arrow represents an incoming RF~(Radio Frequency) pulse. Illustration courtesy of \citet{wiki}.}
    \end{figure}
    }
    \only<3>{
    \begin{figure}
        \centering
        \includegraphics[width=0.5\textwidth]{Figures/intro_figures/Relaxation.pdf}
        \caption{\label{fig:relaxation}\textbf{Illustration of the relaxation phenomenon:} the blue arrow represents an outgoing FID~(Free Induction Decay) pulse. Illustration courtesy of \citet{wiki}.}
    \end{figure}
    }
    % video of e-MRI
\end{frame}

\begin{frame}{Physics of MRI - 2}
    % Because all spins get excited, we get a global RF pulse that is the weighted sum of the contribution of all spins' relaxation RF pulses: global information
    % We can obtain "multiple global information", by changing a bit the magnetic field spatially using gradients
    % Signal equation
    However, the FID carries global information.
    \pause
    
    Using magnetic gradients enables changing a bit the magnetic field spatially, and therefore changing the global information depending on local factors.
    \pause
    
    This allows us to receive a temporal signal of the form:
    \begin{equation}
        \vspace{\baselineskip}
        \tikzmarknode{S}{\highlight{blue}{$S_{tr}(t)$}} \propto \omega_0  \int_{V_s} B_{tr} \tikzmarknode{M}{\highlight{green}{$M_{tr}(t, \rb)$}} e^{-\imath \gamma \rb \cdot \int_0^t \tikzmarknode{G}{\highlight{red}{$\Gb(\tau)$}}  \dif \tau} \dif \rb 
    \end{equation}
    \begin{tikzpicture}[overlay,remember picture,>=stealth,nodes={align=left,inner ysep=1pt},<-]
        % For "S"
        \path (S.south) ++ (0,-2em) node[anchor=south east,color=blue!67] (exp_S){\textbf{Recorded MR signal}};
        \draw [color=blue!87](S.south) |- ([xshift=-0.3ex,color=blue]exp_S.south west);
        % For "M"
        \path (M.south) ++ (0, -6em) node[anchor=south east,color=green!47] (exp_M){\textbf{Magnetic field in each location $\rb$,}\\ \textbf{proportional to the spin density $\rhob(\rb)$}};
        \draw [color=green!87](M.south) |- ([xshift=-0.3ex,color=green]exp_M.south west);
        % For "G"
        \path (G.south) ++ (0, -2em) node[anchor=north west,color=red!47] (exp_G){\textbf{Temporal gradients,}\\\textbf{controlled by the operator}};
        \draw [color=red!87](G.south) |- ([xshift=-0.3ex,color=red]exp_G.south east);
    \end{tikzpicture}
\end{frame}

\begin{frame}{Physics of MRI - 3}
    % Signal equation => k-space
    The k-space vector, $\kb(t) = \frac{\gamma}{2\pi} \int_0^t \Gb(\tau) \dif \tau$, defines how we traverse the Fourier space of the anatomical image.

    % We are sampling in the Fourier space of the anatomical image
    \begin{figure}
        \centering
        \includegraphics[height=0.4\textheight]{Figures/intro_figures/kspace_to_image.pdf}
        \caption{\label{fig:example-kspace}\textbf{Example of a k-space with its corresponding anatomical image}: The raw data is from the fastMRI dataset. The k-space is in log-scale and only the magnitude of the 2 images are represented. We selected only a single coil from the 16 coils available for illustrative purposes.}
    \end{figure}
\end{frame}

\begin{frame}{Physics of MRI - 4}
    % Let's not forget our initial goal here: we want to understand why MRI is slow
    % The relaxation is slow !
    \begin{block}{Recap}
        MRI relies on the nuclear resonance phenomenon. This enables us to sample the Fourier space of the anatomical object of interest.
    \end{block}
    \pause
    MRI is slow, because the relaxation is slow!
\end{frame}

\subsection{Acceleration in MRI}
\begin{frame}{Where is there room for acceleration?}
    % Explain the concept of redundancy
    % first example: partial Fourier => give limits
    \textbf{Redundancy}, otherwise called \textbf{sparsity, symmetry, structure or a priori information}, is the core concept that will help us accelerate MRI.\\
    
    \begin{overprint}
        \onslide<2>
        \hfill \break
    Here is an illustrative example:
    \begin{figure}
        \centering
        \includegraphics[height=0.4\textheight]{Figures/intro_figures/astronaut_masked.pdf}
        \caption{\label{fig:astronaut-masked}\textbf{The inpainting problem.} Even without access to all the pixel values directly, we can infer them, because the information in the image is redundant.
        }
    \end{figure}
    
    \onslide<3>
    \hfill \break
    Here is an illustrative example:
    \begin{figure}
        \centering
        \includegraphics[height=0.4\textheight]{Figures/intro_figures/astronaut.pdf}
        \caption{\label{fig:astronaut}\textbf{The inpainting problem.} Even without access to all the pixel values directly, we can infer them, because the information in the image is redundant.
        }
    \end{figure}
    
    \onslide<4>
        \hfill \break
        Is there a similar thing in MRI?

        Yes! The anatomical image is real-valued so its Fourier Transform~(FT) has a conjugate symmetry.
        Using this redundancy to sample less points in the k-space (i.e. using the relaxation fewer times) is a technique called \textbf{Partial Fourier}.
        
        But in practice it is still needed to sample 6/8 of the Fourier space (acceleration of 1.3).\footfullcite{emri}
    
    \end{overprint}
    
\end{frame}

\begin{frame}{Parallel imaging}
    % "forging" the redundancy
    We can build more redundancy in the measuring system by using \textbf{more antennas (called coils)} to measure the magnetic signal.
    
    This technique is called \textbf{Parallel Imaging~(PI)}. 
    A reconstruction algorithm is now needed to handle the multi-coil undersampled data.
        \textbf{SENSE}\footfullcite{Pruessmann1999SENSE:MRI} and \textbf{GRAPPA}\footfullcite{Griswold2002GeneralizedGRAPPA} are such algorithms.    
    % GRAPPA + SENSE examples
\end{frame}

\begin{frame}{The example of GRAPPA}
    \begin{figure}
        \centering
        \includegraphics[height=0.6\textheight]{Figures/intro_figures/GRAPPA.jpeg}
        \caption{\label{fig:GRAPPA}\textbf{GRAPPA illustration.} Image courtesy of \citet{deshmane2012parallel}.
        }
    \end{figure} 
\end{frame}

\begin{frame}{Limits of Parallel Imaging}
    % Max AF
    % XXX: wait for AV's response
\end{frame}

\section{Compressed Sensing}
\begin{frame}{Another look at redundancy: the prior point of view}
    % give a sense of what structure is and how it relates to redundancy
    Redundancy is not always strict: we may only have a strong correlation between 2 structures of the image.
    \begin{figure}
        \centering
        \includegraphics[height=0.5\textheight]{Figures/cs_figures/smiley_prior.pdf}
        \caption{\label{fig:redundancy-smiley}\textbf{A smiley example to a priori knowledge:} Even if we do not have access to the whole image, we still know which images are more \emph{likely} to correspond to it.
        }
    \end{figure}
\end{frame}

\subsection{Linear Inverse Problems}
\begin{frame}{Linear Inverse Problems}
    % introduce linear inverse problems
    To leverage this type of redundancy, we introduce the concept of \textbf{Linear Inverse Problems}:
    \begin{equation}
        \tikzmarknode{A}{\highlight{green}{$\Ab$}} \tikzmarknode{x}{\highlight{blue}{$\xb$}} = \tikzmarknode{y}{\highlight{yellow}{$\yb$}}
    \end{equation}
    \vspace{2\baselineskip}
    \begin{tikzpicture}[overlay,remember picture,>=stealth,nodes={align=left,inner ysep=1pt},<-]
        % For "A"
        \path (A.south) ++ (0,-2em) node[anchor=south east,color=green!47] (exp_A){\textbf{Measurement operator}};
        \draw [color=green!87](A.south) |- ([xshift=-0.3ex,color=green]exp_A.south west);
        % For "x"
        \path (x.south) ++ (0, -3.5em) node[anchor=south east,color=blue!67] (exp_x){\textbf{Signal to reconstruct}};
        \draw [color=blue!87](x.south) |- ([xshift=-0.3ex,color=blue]exp_x.south west);
        % For "y"
        \path (y.south) ++ (0, -1em) node[anchor=north west,color=yellow!67] (exp_y){\textbf{Measurements}};
        \draw [color=yellow!87](y.south) |- ([xshift=-0.3ex,color=yellow]exp_y.south east);
    \end{tikzpicture}
    % XXX: add tikz figure using the advice of: https://github.com/synercys/annotated_latex_equations

    \pause
    Problems arise when $\ker{\Ab} \neq \{0\}$, i.e. when there are multiple solutions to this equation.

    \pause
    \hfill \break
    In order to select one of these solutions, we need to use a priori knowledge.
\end{frame}

\begin{frame}{Sparsity and Inverse Problems}
    % explain the concept of sparsity and its link to recovery guarantees
    \begin{definition}[Sparsity]
        A vector $\xb \in \mathbb{C}^n$ is called $s$-sparse if it contains at most $s$ non-zero entries.
    \end{definition}

    \begin{lemma}[Optimization reformulation of sparse vector recovery~\citep{Foucart2013SparseSystems}]
        For a given sparsity $s$, and $s$-sparse vector $\xb$:
    \begin{enumerate}[(a)]
        \item The vector $\xb$ is the unique $s$-sparse solution of $\Ab \xb = \yb$, that is $\{\zb \in \mathbb{C}^n : \Ab \zb = \Ab \xb, \|z\|_0 \leq s\} = \{\xb\}$
        \item The vector $\xb$ can be reconstructed as the unique solution of:
        \begin{equation}
            \label{eq:cs-problem-l0-min}
            \min_{\zb \in \mathbb{C}^n} \|\zb\|_0 \quad \text{subject to} \quad \Ab \zb = \yb
        \end{equation}
    \end{enumerate}
    \end{lemma}
\end{frame}

\begin{frame}{Recovery guarantees}
    \begin{theorem}[{{\citep[Theorem~2.13]{Foucart2013SparseSystems}}}]
        The following properties are equivalent:
\begin{enumerate}[(a)]
    \item Every $s$-sparse vector $\xb \in \mathbb{C}^n$ is the unique $s$-sparse solution of $\Ab \zb = \Ab \xb$, that is, if $\Ab \xb = \Ab \zb$ and both $\xb$ and $\zb$ are $s$-sparse, then $\xb = \zb$.
    \item The null space $\ker(\Ab)$ does not contain any $2s$-sparse vector other than the zero.
    \item Every set of $2s$ columns of $\Ab$ is linearly independent.
\end{enumerate}
    \end{theorem}
\end{frame}

\begin{frame}{Application to MRI}
    MR images themselves cannot be represented as sparse vectors directly, we need a way to express them as such.
    \citet{Lustig2007} did that by using the fact that MR images can be represented sparsely in a \textbf{wavelet} basis.

    \hfill \break
    The Inverse Problem becomes:
    \begin{equation}
        \tikzmarknode{FS}{\highlight{green}{$\left(\Ib_L\otimes {\mathcal{F}}_{\Omega}\right)\Sbb$}} \tikzmarknode{x}{\highlight{blue}{$\xb$}} = \tikzmarknode{y}{\highlight{yellow}{$\ybb$}}
    \end{equation}
    \begin{tikzpicture}[overlay,remember picture,>=stealth,nodes={align=left,inner ysep=1pt},<-]
        % For "FS"
        \path (FS.south) ++ (0,-4em) node[anchor=south east,color=green!47] (exp_FS){
            \textbf{$\mathcal{F}_{\Omega}$ : FT on the $\Omega$ set;}\\
            \textbf{$\Sbb=[\Sb_1^H,\ldots, \Sb_L^H]^\top$: the sensitivity maps}\\
            \textbf{per coil}
        };
        \draw [color=green!87](FS.south) |- ([xshift=-0.3ex,color=green]exp_FS.south west);
        % For "x"
        \path (x.south) ++ (0, -2em) node[anchor=south west,color=blue!67] (exp_x){\textbf{2D or 3D MR image}};
        \draw [color=blue!87](x.south) |- ([xshift=-0.3ex,color=blue]exp_x.south east);
        % For "y"
        \path (y.north) ++ (0, 1em) node[anchor=south west,color=yellow!67] (exp_y){$\ybb=[\yb_1^H, \ldots, \yb_L^H]^\top$,\\ \textbf{k-space measurements} \\ \textbf{for each coil}};
        \draw [color=yellow!87](y.north) |- ([xshift=-0.3ex,color=yellow]exp_y.south east);
    \end{tikzpicture}
\end{frame}

\subsection{Recovery Algorithms}
\begin{frame}{Relaxation}
    Now we have an optimization problem to solve, but can we?
    \pause
    No; we need to relax it using the basis pursuit:
    \begin{equation}
        \label{eq:basis-pursuit}
        \min_{\xb \in \mathbb{C}^n} \|\xb\|_1 \quad \text{subject to} \quad \tikzmarknode{calA}{\underline{\mathcal{A}}} \xb = \ybb
    \end{equation}
    \vspace{\baselineskip}
    \begin{tikzpicture}[overlay,remember picture,>=stealth,nodes={align=left,inner ysep=1pt},<-]
        % For "calA"
        \path (calA.south) ++ (0,-2em) node[anchor=south west,color=black!87] (exp_calA){
            $= \left(\Ib_L\otimes {\mathcal{F}}_{\Omega}\right)\Sbb$
        };
        \draw [color=black!87](calA.south) |- ([xshift=-0.3ex,color=black]exp_calA.south east);
    \end{tikzpicture}
    \pause
    For this problem to have the same solutions as the non-relaxed one, we need coherence-based constraints on the measurement operator $\mathcal{A}$.

\end{frame}

\begin{frame}{ISTA}

\end{frame}

\begin{frame}{Dictionary Learning}

\end{frame}


\begin{frame}{Limitations of classical recovery algorithms}
    % give max AF
    % also give a sense of the limitations in compute and in prior learning
\end{frame}

\section{Deep Learning}

\subsection{The power of Deep Learning}
\begin{frame}{The power of Deep Learning}
    % we want to learn a complicated function that tells us whether an image is an MR image
    % similarly deep learning has been able to build functions that tell whether an image is that of a dog or a cat
    % universal approx
\end{frame}

\begin{frame}{Formalism - 1}
    % supervised learning objective function
\end{frame}

\begin{frame}{Formalism - 2}
    % Stochastic Gradient descent and chain rule
\end{frame}

\subsection{Requirements for Deep Learning}
\begin{frame}{Requirements for Deep Learning}
    % Great that I can do that, but does it take ?
    % Data, compute + memory, framework
    % accept that it's "black-box"
\end{frame}

\begin{frame}{Building the network}
    % give classical functions
\end{frame}

\addtocontents{toc}{\newpage}

\section{Deep Learning for MRI}
\subsection{Simple models}
\begin{frame}{Model agnostic learning}
    % reframing the problem as supervised learning
    % no knowledge of the physics imposed in the model
\end{frame}

\begin{frame}{Single domain learning}
    % Use the backward operator as a basis for the restoration model
\end{frame}

\subsection{Unrolled models}
\begin{frame}{Unrolled models - 1}
    % recovery algorithm and corresponding computation graph
    % show on second slice unrolled computation graph
\end{frame}

\begin{frame}{Unrolled models - 2}
    % move from fixed prior to learned one
\end{frame}

\begin{frame}{Unrolled models - 3}
    % first benchmark: different unrolling strategies give different results

\end{frame}

\subsection{New unrolled models}
\begin{frame}{XPDNet}
    % talk about XPDNet archi
\end{frame}

\begin{frame}{fastMRI challenge}
    % mention fastMRI challenge results
\end{frame}

\begin{frame}{NC-PDNet - 1}
    % explain NC-PDNet and density compensation
\end{frame}

\begin{frame}{NC-PDNet - 2}
    % give results
\end{frame}

\begin{frame}{Recap}
    % cool: we are starting to have good results, let's not forget the end goal
    % use this in a scanner so that the MRI exam is faster
    % how will this technique fare in the clinical setting ?
\end{frame}

\section{Clinical applicability}
\subsection{Learnlets}
\begin{frame}{Learnlets - 1}
    % explain that robustness is a key aspect that we have with wavelets
\end{frame}

\begin{frame}{Learnlets - 2}
    % show the Learnlets model
\end{frame}

\begin{frame}{Learnlets - 3}
    % Learnlets results
\end{frame}

\subsection{Denoising Score Matching}
\begin{frame}{Denoising Score Matching - 1}
    % explain what UQ might be used for
\end{frame}

\begin{frame}{Denoising Score Matching - 2}
    % give method of DSM
\end{frame}

\begin{frame}{Denoising Score Matching - 3}
    % give results
\end{frame}

\subsection{Comparison with GRAPPA}
\begin{frame}{Prospective comparison with GRAPPA}
    % show big brain results
    % explain why it's robustness test already
\end{frame}

\begin{frame}{Recap}
    % we have seen how to adapt to clinical setting and answered the question of prospective reconstruction
    % robust : learnlets
    % UQ: DSM
    % propsective: check
\end{frame}

\section{Going even deeper}
\subsection{Implicit models}

\begin{frame}{Why should we go deeper?}
    % with deeper models, comes better performance
    % figure of Pezzotti et al.
\end{frame}

\begin{frame}{Can we go deeper?}
    % in the current state not: activations + constrained memory
\end{frame}

\begin{frame}{The modeling solutions}
    % gradient checkpointing
    % Invertible networks
    % Implicit models
\end{frame}

\begin{frame}{Deep Equilibrium networks}
    % give equation and how to compute the gradient with IFT
\end{frame}

\subsection{SHINE}
\begin{frame}{The limits of DEQs}
    % they are slow to train
\end{frame}

\begin{frame}{Why are DEQs slow?}
    % bc of Jacobian inversion
\end{frame}

\begin{frame}{Can we avoid the Jacobian inversion?}
    % yes: reuse a by-product of the forward pass, share the inverse estimate
\end{frame}

\begin{frame}{Application to Hyperparameter optimization}
    % it's also a bilevel prob
\end{frame}

\begin{frame}{Results on DEQs}

\end{frame}

\section{Conclusion \& Future works}

\begin{frame}{Conclusion}
    % what have we seen so far in the journey?
\end{frame}

\begin{frame}{Future works}
    % DEQs for MRI recon
    % More operator correction
    % Trajectory learning
\end{frame}
%----------------------------------------------------------------------------------------

\begin{frame}[allowframebreaks]{References}
    \printbibliography
\end{frame}

\end{document}